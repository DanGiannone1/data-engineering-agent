"""
MAF Test with REAL data - DNAV Data Dictionary + Effective_Transactions
"""

import asyncio
import json
import os
import sys
from typing import Annotated

from dotenv import load_dotenv
load_dotenv()

sys.path.insert(0, os.path.join(os.path.dirname(__file__), "src"))

from agent_framework import Agent, tool
from agent_framework.azure import AzureOpenAIChatClient
from azure.identity import AzureCliCredential
import pandas as pd


# =============================================================================
# Tools - Read from LOCAL files for this test
# =============================================================================

@tool
def read_dnav_mapping(
    sheet_name: Annotated[str, "Sheet name in DNAV Data Dictionary, e.g. 'Fund Transactions'"]
) -> str:
    """Read mapping rules from DNAV Data Dictionary Excel file."""
    df = pd.read_excel('input_data/JG Copy of DNAV Data Dictionary.xlsx', sheet_name=sheet_name, header=6)

    # Clean up and structure the mapping
    mappings = []
    for _, row in df.iterrows():
        dnav_field = row.get('DNAV Field', '')
        if pd.isna(dnav_field):
            continue

        mapping = {
            'dnav_field': dnav_field,
            'description': row.get('DNAV Field Description', ''),
            'data_type': row.get('Data Type', ''),
            'client_field': row.get('Client Field', ''),
            'source_file': row.get('Field Source File ', ''),
            'formula_notes': row.get('Field Notes', ''),
            'required': row.get('Requirement Level', '')
        }
        mappings.append(mapping)

    return json.dumps(mappings, indent=2, default=str)


@tool
def read_source_data_sample(
    file_name: Annotated[str, "Source file name, e.g. 'Effective_Transactions_sample.csv'"],
    n_rows: Annotated[int, "Number of rows to sample"] = 5
) -> str:
    """Read sample rows from source data file to understand structure."""
    df = pd.read_csv(f'input_data/{file_name}', nrows=n_rows)

    result = {
        'columns': list(df.columns),
        'column_count': len(df.columns),
        'dtypes': {col: str(dtype) for col, dtype in df.dtypes.items()},
        'sample_rows': df.head(n_rows).to_dict(orient='records')
    }

    return json.dumps(result, indent=2, default=str)


@tool
def list_source_columns(
    file_name: Annotated[str, "Source file name"]
) -> str:
    """List all column names in source file (useful for matching to mapping)."""
    df = pd.read_csv(f'input_data/{file_name}', nrows=1)
    return json.dumps({'columns': list(df.columns), 'count': len(df.columns)})


@tool
def generate_pyspark_code(
    code: Annotated[str, "Complete PySpark transformation code"],
    description: Annotated[str, "Brief description of what the code does"]
) -> str:
    """Save generated PySpark code to file for review. Returns the file path."""
    output_path = 'input_data/generated_transform.py'
    with open(output_path, 'w') as f:
        f.write(f'# {description}\n')
        f.write(f'# Generated by MAF Agent\n\n')
        f.write(code)

    return json.dumps({
        'status': 'saved',
        'path': output_path,
        'description': description,
        'code_length': len(code)
    })


# =============================================================================
# Agent Setup
# =============================================================================

AGENT_INSTRUCTIONS = """You are a data engineering agent that transforms client data into DNAV format.

Your task:
1. Read the DNAV mapping rules from the Data Dictionary
2. Read the source data sample to understand its structure
3. Match source columns to DNAV fields (handle case/naming differences)
4. Generate PySpark code that transforms the source data to DNAV format

Key considerations:
- Source column names may not exactly match the mapping - use fuzzy matching
- Some DNAV fields are calculated from formulas in 'formula_notes' (e.g., IF statements)
- Some fields may not have source data - handle nulls appropriately
- The code should be production-ready PySpark using DataFrame API

For calculated fields with formulas like:
  "IF(A_QUOTETYPE="NOM", ABS(100*A_BOOKVALUE_AC/T_AMOUNT), ABS(A_BOOKVALUE_AC/T_AMOUNT))"
Convert these to PySpark F.when() expressions.

Generate complete, runnable PySpark code.
"""


def get_chat_client() -> AzureOpenAIChatClient:
    return AzureOpenAIChatClient(
        azure_endpoint=os.environ["AZURE_OPENAI_ENDPOINT"],
        deployment_name=os.environ["AZURE_OPENAI_DEPLOYMENT"],
        credential=AzureCliCredential(process_timeout=60),
        api_version="2025-01-01-preview",
    )


def create_agent() -> Agent:
    client = get_chat_client()

    return Agent(
        client=client,
        name="DNAVTransformer",
        instructions=AGENT_INSTRUCTIONS,
        tools=[
            read_dnav_mapping,
            read_source_data_sample,
            list_source_columns,
            generate_pyspark_code,
        ],
    )


# =============================================================================
# Main
# =============================================================================

async def main():
    print("=" * 70)
    print("MAF Agent - Real DNAV Transformation Test")
    print("=" * 70)

    agent = create_agent()
    thread = agent.get_new_thread()

    user_request = """Transform Fund Transactions data for a client.

Source file: Effective_Transactions_sample.csv
Mapping: Use 'Fund Transactions' sheet from DNAV Data Dictionary

Please:
1. Read the DNAV mapping for Fund Transactions
2. Read the source data to see the actual column names
3. Match source columns to DNAV fields (the names may differ slightly)
4. Generate PySpark code that performs the transformation
5. Handle calculated fields (those with formulas in the notes)

Focus on the fields from 'Effective_Transactions' source file only (not 'Recalculate' fields for now).
"""

    print(f"\nRequest: Transform Fund Transactions using DNAV mapping")
    print("=" * 70)

    response = await agent.run(user_request, thread=thread)

    print("\n" + "=" * 70)
    print("AGENT RESPONSE")
    print("=" * 70)

    if hasattr(response, 'text') and response.text:
        print(response.text)

    # Show tool calls
    if hasattr(response, 'messages') and response.messages:
        print("\n--- TOOL CALLS ---")
        for msg in response.messages:
            if hasattr(msg, 'contents') and msg.contents:
                for content in msg.contents:
                    if hasattr(content, 'name') and content.name:
                        print(f"  [{content.name}]")


if __name__ == "__main__":
    asyncio.run(main())
